---
description: Apply these rules when making changes to the project
globs:
alwaysApply: true
---

Update this rule if user requested changes to the project requirement, etc.
# Project Requirements Document (PRD): DShield-SIEM

## 1. Project Overview

DShield-SIEM is a specialized Security Information and Event Management system built on the Elastic Stack (Elasticsearch, Logstash, Kibana, Beats). Its core purpose is to collect, parse, enrich, store, and visualize security logs—especially from DShield sensors which include Cowrie honeypots, webhoneypots, firewall (iptables), and Zeek network monitors. By unifying diverse log types and integrating external threat intelligence feeds (ISC, Rosti, VirusTotal), it helps security analysts detect, investigate, and respond to incidents faster.

This system is being built to give incident responders and network administrators a turnkey solution for threat hunting and real-time alerting. Success will be measured by:

*   Timely ingestion and enrichment of DShield and related logs
*   Clear, interactive dashboards in Kibana that cover honeypot activity, network flows, and IOC matches
*   Reliable alerting on suspicious patterns (failed logins, malware hashes)
*   Ease of deployment via Docker Compose and straightforward configuration through provided scripts

## 2. In-Scope vs. Out-of-Scope

**In-Scope (Version 1.0):**

*   Data ingestion from DShield sensors (Cowrie SSH/Telnet honeypot, webhoneypot), iptables, Zeek logs
*   Log parsing and enrichment via Logstash pipelines (Grok, GeoIP, threat Intel lookups)
*   Threat intelligence integration: ISC IP Intel, Rosti Intel, VirusTotal API
*   Storage and indexing in Elasticsearch with ILM (index lifecycle management)
*   Prebuilt Kibana dashboards and visualizations for key security event types
*   Basic alerting rules in Kibana (e.g., multiple failed logins, IOC matches)
*   Containerized deployment using Docker + Docker Compose
*   Shell scripts for initial setup (certificate creation, index templates, dashboard import)
*   Automated honeypot setup
*   Secret storage using a modular secret backend (1Password, Hashicorp Vault, Azure Key Vault, etc.)
*   Bulk Data load from pre-existing sensors, or for Disaster recovery, must be able to date ingested events properly

** In-Scope (Version 2.0)**

*   High-availability Elasticsearch setups, using K8s/K3s
*   Deep integration with dsheild-mcp ([https://github.com/datagen24/dsheild-mcp](https://github.com/datagen24/dsheild-mcp/issues)) 
*   Custom machine learning anomaly detection via integration with dshield-coordination-engine 
*   Connection with public or Private MISP servers for threat Analysis
*   Automated setup of honeypots

**Out-of-Scope (Phase 3+):**

*   iPhone push notifications for interesting events
*   User management beyond Elasticsearch native roles, to allow collective research
*   Deep packet capture storage (Arkime integration only documented, not baked in) or security onion collection from the multitude of sensors
*   Potential port to allow this to work on Elastic Cloud to support enterprise features
*   Logstash Pipelines managed in Elastic
*   Integration of other honeypot systems, with cross-enrichment

## 3. User Flow

A security analyst logs into the Kibana web interface using their credentials. Upon landing, they see a home dashboard that summarizes the overall security posture, including event rates, top offending IPs, and recent alert history. From the left-hand menu, they navigate to the “Honeypot Activity” dashboard, which breaks down Cowrie SSH/Telnet login attempts, executed commands, and file transfer events. The analyst can click on any graph or table entry to drill into raw log details in the Discover view, using Kibana Query Language (KQL) to refine the search.

Next, the analyst switches to the “Threat Intelligence” tab to review recent IOC matches—failed logins or file hashes flagged by ISC or VirusTotal. If a critical alert (e.g., multiple login failures from a single IP) is active, it appears in the Alerts panel. The analyst acknowledges or silences the alert, then may create a new alert rule for emerging patterns. Throughout, all dashboards auto-refresh at a user-defined interval (e.g., every 30 seconds), ensuring near real-time visibility as new logs arrive.

## 4. Core Features

*   **Log Collection & Ingestion**\
    • Filebeat for tailing DShield sensor logs and generic syslogs\
    • Metricbeat for host and container metrics\
    • Heartbeat for uptime checks\
    • Elastic Agent for unified collection (optional)\
    • Secure forwarding to Logstash
*   **Log Processing & Enrichment**\
    • Logstash pipelines with Grok, Mutate, Drop filters per log type\
    • GeoIP plugin for IP geolocation\
    • Threat Intel lookups against ISC, Rosti, VirusTotal\
    • Normalization to Elastic Common Schema (ECS)
*   **Data Storage & Indexing**\
    • Elasticsearch clusters (single node in v1.0)\
    • ILM policies for index rollover, retention, deletion\
    • Optimized mappings for efficient search
*   **Visualization & Analysis**\
    • Prebuilt Kibana dashboards: honeypot, network flows, firewall events, IOC matches\
    • Custom visualizations (charts, tables, maps)\
    • Discover view with KQL for ad-hoc queries
*   **Threat Detection & Alerting**\
    • IOC-based rules (malicious IPs, domains, file hashes)\
    • Behavioral rules (e.g., > X failed logins in Y minutes)\
    • Email notifications for critical alerts
*   **Deployment & Management**\
    • Docker images for all Elastic Stack components\
    • Docker Compose orchestration file\
    • Bash scripts for initial setup, certificate generation, dashboard import\
    • Markdown guides for add-ons (Arkime, Zeek tuning, packet capture)

## 5. Tech Stack & Tools

*   **Backend & Data Pipeline**\
    • Elasticsearch (storage & search)\
    • Logstash (ingest, parse, enrich)\
    • Filebeat, Metricbeat, Heartbeat, Elastic Agent (data shippers)
*   **Frontend & Visualization**\
    • Kibana (dashboards, Discover, alerting)
*   **Containerization**\
    • Docker, Docker Compose
*   **Scripting & Automation**\
    • Bash / Shell scripts\
    • Python (for custom VirusTotal enrichment scripts)
*   **Config & Data Formats**\
    • YAML (Beats, Logstash, Docker Compose)\
    • JSON / NDJSON (Logstash config, Kibana saved objects, bulk imports)
*   **Threat Intelligence**\
    • ISC IP Threat Feed, Rosti Feed, VirusTotal API
*   **Sensors & Tools**\
    • Cowrie honeypot, Webhoneypot, Zeek, iptables\
    • GeoIP plugin
*   **AI-Powered Dev Tools**\
    • Claude Code (AI coding assistant in terminal)\
    • Cursor (IDE plugin for AI suggestions)\
    • Xcode (for Mac-based scripting and plugin development)

## 6. Non-Functional Requirements

*   **Performance:**\
    • Ingest 1,000+ events/sec with < 2 sec processing latency\
    • Dashboards load in < 3 sec for standard queries
*   **Scalability:**\
    • Support horizontal scaling of Elasticsearch nodes
*   **Security:**\
    • TLS encryption for Beats → Logstash → Elasticsearch traffic\
    • Role-based access control in Kibana / Elasticsearch
*   **Reliability & Availability:**\
    • Docker Compose restarts on failure\
    • Health checks via Heartbeat
*   **Usability:**\
    • Clear naming conventions for indices (e.g., `siem-cowrie-YYYY.MM.DD`)\
    • Intuitive dashboards with consistent color schemes
*   **Compliance:**\
    • Retention policies aligned to 90 days of hot data, 180 days of warm storage

## 7. Constraints & Assumptions

*   Elasticsearch will initially run as a single-node cluster (HA not required in v1.0).
*   Docker and Docker Compose must be available on target hosts.
*   Threat feeds (ISC, Rosti, VirusTotal) require valid API keys.
*   Bash scripting is acceptable for automation; no complex orchestration tool required.
*   Users have basic familiarity with Kibana and KQL.

## 8. Known Issues & Potential Pitfalls

*   **API Rate Limits:** VirusTotal and ISC feeds may throttle requests—implement caching or backoff retries.
*   **Logstash Pipeline Performance:** Complex Grok patterns can slow ingestion; tune or precompile patterns.
*   **Disk Space Growth:** Without proper ILM, indices can exhaust storage—validate ILM policies early.
*   **Time Skew:** Sensor hosts must sync clock via NTP to avoid log timestamp inaccuracies.
*   **Configuration Drift:** Provide versioned Docker Compose files and configuration templates to avoid drift across environments.
*   **Kibana Object Import Errors:** Ensure NDJSON versions match Kibana version to prevent import failures.

This PRD provides a clear blueprint for DShield-SIEM’s current version and planned features, covering objectives, scope, user interactions, core modules, technology choices, and operational guidelines. Subsequent technical documents (Tech Stack, Frontend Guidelines, Backend Structure, etc.) can be derived directly from this specification without ambiguity.
